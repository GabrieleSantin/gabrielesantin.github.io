[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m a Researcher in the MobS Lab at the Center for Information and Communication Technology of the Fondazione Bruno Kessler in Trento (IT).\nI work with the RSDE and DCL labs to develope Machine Learning solutions and algorithms for the exploitation of different data sources and modeling techniques within the \u0026ldquo;City Sensing\u0026rdquo; project.\nI\u0026rsquo;m also a junior partecipating researcher in the Cluster of Excellence Data-integrated Simulation Science, where I\u0026rsquo;m a member of the Project Network Machine Learning for Simulation.\nPreviously, I\u0026rsquo;ve been for four years in the group of Bernard Haasdonk at the University of Stuttgart, working on kernel based algorithms and their application to the surrogate modelling of complex simulations.\nI obtained my MSc and PhD at the Department of Mathematics of the University of Padova under the supervision of Stefano De Marchi in the CAA group, where I wrote my theses on algorithmic and theoretical aspects of kernel based interpolation.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://GabrieleSantin.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I\u0026rsquo;m a Researcher in the MobS Lab at the Center for Information and Communication Technology of the Fondazione Bruno Kessler in Trento (IT).\nI work with the RSDE and DCL labs to develope Machine Learning solutions and algorithms for the exploitation of different data sources and modeling techniques within the \u0026ldquo;City Sensing\u0026rdquo; project.\nI\u0026rsquo;m also a junior partecipating researcher in the Cluster of Excellence Data-integrated Simulation Science, where I\u0026rsquo;m a member of the Project Network Machine Learning for Simulation.","tags":null,"title":"Gabriele Santin","type":"authors"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"9169562411f47984b1acb0770bb72c6c","permalink":"https://GabrieleSantin.github.io/publication/bruennette2019/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/bruennette2019/","section":"publication","summary":"We present a novel acceleration method for the solution of parametric ODEs by single-step implicit solvers by means of greedy kernel-based surrogate models. In an offline phase, a set of trajectories is precomputed with a high-accuracy ODE solver for a selected set of parameter samples, and used to train a kernel model which predicts the next point in the trajectory as a function of the last one. This model is cheap to evaluate, and it is used in an online phase for new parameter samples to provide a good initialization point for the nonlinear solver of the implicit integrator. The accuracy of the surrogate reflects into a reduction of the number of iterations until convergence of the solver, thus providing an overall speedup of the full simulation. Interestingly, in addition to providing an acceleration, the accuracy of the solution is maintained, since the ODE solver is still used to guarantee the required precision. Although the method can be applied to a large variety of solvers and different ODEs, we will present in details its use with the Implicit Euler method for the solution of the Burgers equation, which results to be a meaningful test case to demonstrate the method's features.","tags":null,"title":"Greedy kernel methods for accelerating implicit integrators for parametric ODEs","type":"publication"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"7667ced3d27f05b66269f01ff1e536e9","permalink":"https://GabrieleSantin.github.io/publication/hamzi2019/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/hamzi2019/","section":"publication","summary":"For certain dynamical systems it is possible to significantly simplify the study of stability by means of the center manifold theory. This theory allows to isolate the complicated asymptotic behavior of the system close to a non-hyperbolic equilibrium point, and to obtain meaningful predictions of its behavior by analyzing a reduced dimensional problem. Since the manifold is usually not known, approximation methods are of great interest to obtain qualitative estimates. In this work, we use a data-based greedy kernel method to construct a suitable approximation of the manifold close to the equilibrium. The data are collected by repeated numerical simulation of the full system by means of a high-accuracy solver, which generates sets of discrete trajectories that are then used to construct a surrogate model of the manifold. The method is tested on different examples which show promising performance and good accuracy.","tags":null,"title":"Greedy kernel methods for center manifold approximation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"190ca37243b0f5212f9c20beaa898ca0","permalink":"https://GabrieleSantin.github.io/publication/santin2019/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/santin2019/","section":"publication","summary":"This chapter deals with kernel methods as a special class of techniques for surrogate modeling. Kernel methods have proven to be efficient in machine learning, pattern recognition and signal analysis due to their flexibility, excellent experimental performance and elegant functional analytic background. These data-based techniques provide so called kernel expansions, i.e., linear combinations of kernel functions which are generated from given input-output point samples that may be arbitrarily scattered. In particular, these techniques are meshless, do not require or depend on a grid, hence are less prone to the curse of dimensionality, even for high-dimensional problems. In contrast to projection-based model reduction, we do not necessarily assume a high-dimensional model, but a general function that models input-output behavior within some simulation context. This could be some micro-model in a multiscale-simulation, some submodel in a coupled system, some initialization function for solvers, coefficient function in PDEs, etc. First, kernel surrogates can be useful if the input-output function is expensive to evaluate, e.g. is a result of a finite element simulation. Here, acceleration can be obtained by sparse kernel expansions. Second, if a function is available only via measurements or a few function evaluation samples, kernel approximation techniques can provide function surrogates that allow global evaluation. We present some important kernel approximation techniques, which are kernel interpolation, greedy kernel approximation and support vector regression. Pseudo-code is provided for ease  of reproducibility. In order to illustrate the main features, commonalities and differences, we compare these techniques on a real-world application. The experiments clearly indicate the enormous acceleration potential.","tags":null,"title":"Kernel Methods for Surrogate Modeling","type":"publication"},{"authors":null,"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"3a836ac759cbe51aa270e7201e5d4539","permalink":"https://GabrieleSantin.github.io/publication/koeppel2018/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/koeppel2018/","section":"publication","summary":"A variety of methods is available to quantify uncertainties arising within the modeling of flow and transport in carbon dioxide storage, but there is a lack of thorough comparisons. Usually, raw data from such storage sites can hardly be described by theoretical statistical distributions since only very limited data is available. Hence, exact information on distribution shapes for all uncertain parameters is very rare in realistic applications. We discuss and compare four different methods tested for data-driven uncertainty quantification based on a benchmark scenario of carbon dioxide storage. In the benchmark, for which we provide data and code, carbon dioxide is injected into a saline aquifer modeled by the nonlinear capillarity-free fractional flow formulation for two incompressible fluid phases, namely carbon dioxide and brine. To cover different aspects of uncertainty quantification, we incorporate various sources of uncertainty such as uncertainty of boundary conditions, of conceptual model definitions and of material properties. We consider recent versions of the following non-intrusive and intrusive uncertainty quantification methods: arbitary polynomial chaos, spatially adaptive sparse grids, kernel-based greedy interpolation and hybrid stochastic Galerkin. The performance of each approach is demonstrated assessing expectation value and standard deviation of the carbon dioxide saturation against a reference statistic based on Monte Carlo sampling. We compare the convergence of all methods reporting on accuracy with respect to the number of model runs and resolution. Finally we offer suggestions about the methods' advantages and disadvantages that can guide the modeler for uncertainty quantification in carbon dioxide storage and beyond.","tags":["tag1","tag2"],"title":"Comparison of data-driven uncertainty quantification methods for a carbon dioxide storage benchmark scenario","type":"publication"},{"authors":null,"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"28925440c0990bfc081223900437bfb5","permalink":"https://GabrieleSantin.github.io/publication/santin2018/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/santin2018/","section":"publication","summary":"We implement in Matlab a Gauss-like cubature formula on bivariate domains whose boundary is a piecewise smooth Jordan curve (curvilinear polygons). The key tools are Green’s integral formula, together with the recent software package Chebfun to approximate the boundary curve close to machine precision by piecewise Chebyshev interpolation. Several tests are presented, including some comparisons of this new routine ChebfunGauss with the recent SplineGauss that approximates the boundary by splines.","tags":["tag1","tag2"],"title":"Greedy kernel approximation for sparse surrogate modelling.","type":"publication"},{"authors":null,"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"19fdb7309716dea9912eb20aa75c592f","permalink":"https://GabrieleSantin.github.io/publication/demarchi2018/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/demarchi2018/","section":"publication","summary":"We propose a novel kernel-based method for image reconstruction from scattered Radon data. To this end, we employ generalized Hermite--Birkhoff interpolation by positive definite kernel functions. For radial kernels, however, a straightforward application of the generalized Hermite--Birkhoff interpolation method fails to work, as we prove in this paper. To obtain a well-posed reconstruction scheme for scattered Radon data, we introduce a new class of weighted positive definite kernels, which are symmetric but not radially symmetric. By our construction, the resulting weighted kernels are combinations of radial positive definite kernels and positive weight functions. This yields very flexible image reconstruction methods, which work for arbitrary distributions of Radon lines. We develop suitable representations for the weighted basis functions and the symmetric positive definite kernel matrices that are resulting from the proposed reconstruction scheme. For the relevant special case, where Gaussian radial kernels are combined with Gaussian weights, explicit formulae for the weighted Gaussian basis functions and the kernel matrices are given. Supporting numerical examples are finally presented.","tags":null,"title":"Image reconstruction from scattered Radon data by weighted positive definite kernel functions","type":"publication"},{"authors":null,"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"097e039bf062df44282ea569a88bca1d","permalink":"https://GabrieleSantin.github.io/publication/wittwar2018/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/wittwar2018/","section":"publication","summary":"In this paper we consider the problem of approximating vector-valued functions over a domain Ω. For this purpose, we use matrix-valued reproducing kernels, which can be related to Reproducing kernel Hilbert spaces of vectorial functions and which can be viewed as an extension of the scalar-valued case. These spaces seem promising, when modelling correlations between the target function components, as the components are not learned independently of each other. We focus on the interpolation with such matrix-valued kernels. We derive error bounds for the interpolation error in terms of a generalized power-function and we introduce a subclass of matrix-valued kernels whose power-functions can be traced back to the power-function of scalar-valued reproducing kernels. Finally, we apply these kind of kernels to some artificial data to illustrate the benefit of interpolation with matrix-valued kernels in comparison to a componentwise approach.","tags":null,"title":"Interpolation with uncoupled separable matrix-valued kernels","type":"publication"},{"authors":null,"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"8550107183d57b9ebf4e54e1b43bd767","permalink":"https://GabrieleSantin.github.io/publication/koeppl2018/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/koeppl2018/","section":"publication","summary":"In this work, we consider two kinds of model reduction techniques to simulate blood flow through the largest systemic arteries, where a stenosis is located in a peripheral artery i.e. in an artery that is located far away from the heart. For our simulations we place the stenosis in one of the tibial arteries belonging to the right lower leg (right post tibial artery). The model reduction techniques that are used are on the one hand dimensionally reduced models (1-D and 0-D models, the so-called mixed-dimension model) and on the other hand surrogate models produced by kernel methods. Both methods are combined in such a way that the mixed-dimension models yield training data for the surrogate model, where the surrogate model is parametrised by the degree of narrowing of the peripheral stenosis. By means of a well-trained surrogate model, we show that simulation data can be reproduced with a satisfactory accuracy and that parameter optimisation or state estimation problems can be solved in a very efficient way. Furthermore it is demonstrated that a surrogate model enables us to present after a very short simulation time the impact of a varying degree of stenosis on blood flow, obtaining a speedup of several orders over the full model.","tags":null,"title":"Numerical modelling of a peripheral arterial stenosis using dimensionally  reduced models and kernel methods","type":"publication"},{"authors":null,"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"a7a0d4b6451e7141525e000ba7c3ba9b","permalink":"https://GabrieleSantin.github.io/publication/demarchi2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/demarchi2017/","section":"publication","summary":"In the recent paper [8], a new method to compute stable kernel-based interpolants has been presented. This rescaled interpolation method combines the standard kernel interpolation with a properly defined rescaling operation, which smooths the oscillations of the interpolant. Although promising, this procedure lacks a systematic theoretical investigation. Through our analysis, this novel method can be understood as standard kernel interpolation by means of a properly rescaled kernel. This point of view allow us to consider its error and stability properties.","tags":["tag1","tag2"],"title":"A rescaled method for RBF approximation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"2e171c02c352d16c1b80efaf1663944c","permalink":"https://GabrieleSantin.github.io/publication/santin2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/santin2017/","section":"publication","summary":"Kernel-based methods provide flexible and accurate algorithms for the reconstruction of functions from meshless samples. A major question in the use of such methods is the influence of the samples locations on the behavior of the approximation, and feasible optimal strategies are not known for general problems. Nevertheless, efficient and greedy point-selection strategies are known. This paper gives a proof of the convergence rate of the data-independent \textit{P-greedy} algorithm, based on the application of the convergence theory for greedy algorithms in reduced basis methods. The resulting rate of convergence is shown to be near-optimal in the case of kernels generating Sobolev spaces. As a consequence, this convergence rate proves that, for kernels of Sobolev spaces, the points selected by the algorithm are asymptotically uniformly distributed, as conjectured in the paper where the algorithm has been introduced.","tags":null,"title":"Convergence rate of the data-independent P-greedy algorithm in kernel-based spaces","type":"publication"},{"authors":null,"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"d8ce255bb168999e33b8a60deb95aa32","permalink":"https://GabrieleSantin.github.io/publication/cavoretto2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/cavoretto2017/","section":"publication","summary":"In this paper we propose a new stable and accurate approximation technique which is extremely effective for interpolating large scattered data sets. The Partition of Unity (PU) method is performed considering Radial Basis Functions (RBFs) as local approximants and using locally supported weights. In particular, the approach consists in computing, for each PU subdomain, a stable basis. Such technique, taking advantage of the local scheme, leads to a significant benefit in terms of stability, especially for flat kernels. Furthermore, an optimized searching procedure is applied to build the local stable bases, thus rendering the method more efficient.","tags":null,"title":"Partition of unity interpolation using stable kernel-based techniques","type":"publication"},{"authors":null,"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"35beaaf2227148280c00440c3ffb17bc","permalink":"https://GabrieleSantin.github.io/publication/cavoretto2016/","publishdate":"2016-01-01T00:00:00Z","relpermalink":"/publication/cavoretto2016/","section":"publication","summary":"In applied sciences it is often required to model and supervise temporal evolution of populations via dynamical systems. In this paper, we focus on the problem of approximating the basins of attraction of such models for each stable equilibrium point. We propose to reconstruct the basins via an implicit interpolant using stable radial bases, obtaining the surfaces by partitioning the phase space into disjoint regions. An application to a competition model presenting jointly three stable equilibria is considered.","tags":null,"title":"Approximating basins of attraction for dynamical systems via stable radial bases","type":"publication"},{"authors":null,"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"53dc664622c2c0e29be92d8d6c21c39c","permalink":"https://GabrieleSantin.github.io/publication/santin2016/","publishdate":"2016-01-01T00:00:00Z","relpermalink":"/publication/santin2016/","section":"publication","summary":"Kernel-based methods in Numerical Analysis have the advantage of yielding optimal recovery processes in the native Hilbert space $H$ in which they are reproducing. Continuous kernels on compact domains have an expansion into eigenfunctions that are both $L_2$-orthonormal and orthogonal in $H$ (Mercer expansion). This paper examines the corresponding eigenspaces and proves that they have optimality properties among all other subspaces of $H$. These results have strong connections to n-widths in Approximation Theory, and they establish that errors of optimal approximations are closely related to the decay of the eigenvalues. Though the eigenspaces and eigenvalues are not readily available, they can be well approximated using the standard n-dimensional subspaces spanned by translates of the kernel with respect to n nodes or centers. We give error bounds for the numerical approximation of the eigensystem via such subspaces. A series of examples shows that our numerical technique via a greedy point selection strategy allows to calculate the eigensystems with good accuracy.","tags":null,"title":"Approximation of eigenfunctions in kernel-based spaces","type":"publication"},{"authors":null,"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"35eab7d461c461d0163d5c77388cd8ab","permalink":"https://GabrieleSantin.github.io/publication/demarchi2015/","publishdate":"2015-01-01T00:00:00Z","relpermalink":"/publication/demarchi2015/","section":"publication","summary":"In recent years, in the setting of radial basis function, the study of approximation algorithms has particularly focused on the construction of (stable) bases for the associated Hilbert spaces. One of the ways of describing such spaces and their properties is the study of a particular integral operator and its spectrum. We proposed in a recent work the so-called WSVD basis, which is strictly connected to the eigen-decomposition of this operator and allows to overcome some problems related to the stability of the computation of the approximant for a wide class of radial kernels. Although effective, this basis is computationally expensive to compute. In this paper we discuss a method to improve and compute in a fast way the basis using methods related to Krylov subspaces. After reviewing the connections between the two bases, we concentrate on the properties of the new one, describing its behavior by numerical tests.","tags":null,"title":"Fast computation of orthonormal basis for RBF spaces through Krylov space methods","type":"publication"},{"authors":null,"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"b337320f53b13993041487358f6dbade","permalink":"https://GabrieleSantin.github.io/publication/cavoretto2015/","publishdate":"2015-01-01T00:00:00Z","relpermalink":"/publication/cavoretto2015/","section":"publication","summary":"We present an algorithm to approximate large datasets by Radial Basis Function(RBF) techniques. The method couples a fast domain decomposition procedure with alocalized stabilization method. The resulting algorithm can efficiently deal with largeproblems and it is robust with respect to the typical instability of kernel methods.","tags":null,"title":"RBF approximation of large datasets by partition of unity and local stabilization","type":"publication"},{"authors":null,"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"064e1ba9963f82020e3da60bc29fbf53","permalink":"https://GabrieleSantin.github.io/publication/demarchi2013/","publishdate":"2013-01-01T00:00:00Z","relpermalink":"/publication/demarchi2013/","section":"publication","summary":"","tags":null,"title":"A new stable basis for radial basis function interpolation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"19a64ff5e7b1f2a1fb961d607266e6ff","permalink":"https://GabrieleSantin.github.io/publication/santin2011/","publishdate":"2011-01-01T00:00:00Z","relpermalink":"/publication/santin2011/","section":"publication","summary":"We implement in Matlab a Gauss-like cubature formula on bivariate domains whose boundary is a piecewise smooth Jordan curve (curvilinear polygons). The key tools are Green’s integral formula, together with the recent software package Chebfun to approximate the boundary curve close to machine precision by piecewise Chebyshev interpolation. Several tests are presented, including some comparisons of this new routine ChebfunGauss with the recent SplineGauss that approximates the boundary by splines.","tags":["tag1","tag2"],"title":"An algebraic cubature formula on curvilinear polygons","type":"publication"}]